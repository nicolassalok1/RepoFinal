{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LCHWqMbXyg59"
   },
   "outputs": [],
   "source": [
    "#libraries\n",
    "#----------------------------------------------------------------------------\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Input\n",
    "from tensorflow.keras.models import Model\n",
    "#----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_corr_from_yfinance(tickers, period='1mo', fallback=None):\n",
    "    \"\"\"\n",
    "    Calcule dynamiquement une matrice de corrélation\n",
    "    à partir des prix de clôture sur `period` des tickers donnés.\n",
    "\n",
    "    - tickers : liste de tickers Yahoo Finance (ex: ['AAPL','SPY','MSFT']).\n",
    "    - period  : fenêtre temporelle (ex: '1mo', '3mo').\n",
    "    - fallback: matrice numpy (ou None). Si yfinance échoue, cette matrice est renvoyée.\n",
    "\n",
    "    Si aucune donnée n'est récupérée et qu'aucun fallback n'est fourni, une RuntimeError est levée.\n",
    "    \"\"\"\n",
    "    if isinstance(tickers, str):\n",
    "        tickers = [tickers]\n",
    "\n",
    "    # Désactive les configs d'impersonation qui posent problème dans certains environnements\n",
    "    os.environ.pop('YF_IMPERSONATE', None)\n",
    "    os.environ.pop('YF_SCRAPER_IMPERSONATE', None)\n",
    "    try:\n",
    "        yf.set_config(proxy=None)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        data = yf.download(\n",
    "            tickers=tickers,\n",
    "            period=period,\n",
    "            interval='1d',\n",
    "            auto_adjust=True,\n",
    "            progress=False,\n",
    "        )\n",
    "    except Exception as exc:\n",
    "        if fallback is not None:\n",
    "            print(\"Téléchargement yfinance échoué ({}), utilisation du fallback.\".format(exc))\n",
    "            return fallback\n",
    "        raise\n",
    "\n",
    "    if data.empty:\n",
    "        if fallback is not None:\n",
    "            print(\"Aucune donnée récupérée, utilisation du fallback.\")\n",
    "            return fallback\n",
    "        raise RuntimeError(\"Aucune donnée de prix récupérée via yfinance pour les tickers fournis.\")\n",
    "\n",
    "    # Gestion du MultiIndex (colonnes) retourné par yfinance pour plusieurs tickers\n",
    "    if isinstance(data.columns, pd.MultiIndex):\n",
    "        if 'Adj Close' in data.columns.levels[0]:\n",
    "            prices = data['Adj Close']\n",
    "        else:\n",
    "            prices = data['Close']\n",
    "    else:\n",
    "        # Cas d'un seul ticker\n",
    "        if 'Adj Close' in data.columns:\n",
    "            prices = data[['Adj Close']].copy()\n",
    "        elif 'Close' in data.columns:\n",
    "            prices = data[['Close']].copy()\n",
    "        else:\n",
    "            if fallback is not None:\n",
    "                print(\"Colonnes de prix introuvables, utilisation du fallback.\")\n",
    "                return fallback\n",
    "            raise RuntimeError(\"Colonnes de prix introuvables dans les données yfinance.\")\n",
    "        prices.columns = tickers\n",
    "\n",
    "    # Rendements log quotidiens\n",
    "    returns = np.log(prices / prices.shift(1)).dropna(how='any')\n",
    "    if returns.empty:\n",
    "        if fallback is not None:\n",
    "            print(\"Pas assez de données de rendements, utilisation du fallback.\")\n",
    "            return fallback\n",
    "        raise RuntimeError(\"Pas assez de données de rendements pour calculer la corrélation.\")\n",
    "\n",
    "    corr_mat = returns.corr().values\n",
    "    return corr_mat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gG-FVJxgzJDS"
   },
   "source": [
    "\n",
    "# Build and train a neural network model for pricing European Basket options under Black-Scholes assumptions.\n",
    "\n",
    "In order to train a neural network we will need to generate data.\n",
    "\n",
    "1.   Data Generation\n",
    "2.   Building Model\n",
    "\n",
    "**Methodology**\n",
    "\n",
    "The first step is to create a set of combinations of model, option and market parameters (strike, maturities, volatility, riskfree rate, ...)\n",
    "\n",
    "For the multi-asset case (basket option), the Scipy implementation of the numerically stable algorithm of Davies &\n",
    "Higham is used to generate random correlation matrices of\n",
    "underlyings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WmGsev3a1azr"
   },
   "outputs": [],
   "source": [
    "#Global Variables :\n",
    "\n",
    "# number of epochs to train the model on\n",
    "EPOCHS = 50\n",
    "\n",
    "BASE_PRICE   = 100\n",
    "BASE_STRIKE  = 200\n",
    "\n",
    "# Tickers sous-jacents (seront déduits du CSV de clôtures)\n",
    "ASSETS = []\n",
    "\n",
    "# Corrélation calculée plus bas à partir du CSV de clôtures.\n",
    "# CORR_FALLBACK peut être utilisée si besoin.\n",
    "CORR = None\n",
    "CORR_FALLBACK = np.array([\n",
    "    [1.0, 0.6, 0.4],\n",
    "    [0.6, 1.0, 0.7],\n",
    "    [0.4, 0.7, 1.0],\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du CSV de clôtures et calcul de la corrélation\n",
    "closing_csv = 'data/closing_prices.csv'\n",
    "closing_df = pd.read_csv(closing_csv)\n",
    "# On suppose les colonnes : Date, et une colonne par ticker (ex: SPY, AAPL, MSFT)\n",
    "price_cols = [c for c in closing_df.columns if c.lower() != 'date']\n",
    "ASSETS = price_cols  # met à jour la liste des tickers\n",
    "returns = np.log(closing_df[price_cols] / closing_df[price_cols].shift(1)).dropna(how='any')\n",
    "CORR = returns.corr().values\n",
    "CORR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "alCZ5fRKzIL5"
   },
   "outputs": [],
   "source": [
    "class BasketOption:\n",
    "  \"\"\"\n",
    "  Basket class\n",
    "  \"\"\"\n",
    "  def __init__(self, weights, prices, volatility, corr, strike, maturity, rate):\n",
    "    \"\"\"\n",
    "    args:\n",
    "    - matuity : in years\n",
    "    \"\"\"\n",
    "    self.weights = weights\n",
    "    self.vol = volatility\n",
    "    self.strike = strike\n",
    "    self.mat = maturity\n",
    "    self.rate = rate\n",
    "    self.corr = corr\n",
    "    self.prices = prices\n",
    "\n",
    "\n",
    "  def get_mc(self, M=10000):\n",
    "    \n",
    "    '''\n",
    "    reference : https://github.com/shrentseng/Numerical-methods-for-option-pricing/blob/main/Monte%20Carlo%20simulation%20option%20pricing.ipynb\n",
    "    runs M paths of MC\n",
    "    \n",
    "    '''\n",
    "    #B_Ts = np.random.normal(0, self.mat, M)\n",
    "    B_Ts = stats.multivariate_normal(np.zeros(len(self.weights)), cov=self.corr).rvs(size=M)\n",
    "    S_Ts = self.prices * np.exp((self.rate - 0.5 * self.vol ** 2) * self.mat + self.vol * B_Ts)\n",
    "    if len(self.weights) > 1:\n",
    "      payoffs = (np.sum(self.weights * S_Ts, axis=1) - self.strike).clip(0)\n",
    "    else:    \n",
    "      payoffs = np.maximum(S_Ts - self.strike, np.zeros(M)) \n",
    "    self.mc_price = np.mean(payoffs) \n",
    "    return np.exp(-1 * self.rate * self.mat) * self.mc_price\n",
    "\n",
    "\n",
    "  def get_bs_price(self):\n",
    "        d1 = 1 / (self.vol * (self.mat) ** 0.5) * (np.log(self.prices/self.strike)\\\n",
    "                                            + (self.rate + (0.5 * self.vol ** 2)) * self.mat)\n",
    "        d2 = d1 - self.vol * self.mat ** 0.5\n",
    "        self.bs_price = stats.norm.cdf(d1) * self.prices\\\n",
    "                        - stats.norm.cdf(d2) * self.strike * np.exp(-self.rate * self.mat)\n",
    "        \n",
    "        return self.bs_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WYqeMov_z4Gt"
   },
   "outputs": [],
   "source": [
    "class DataGen:\n",
    "  \"\"\"\n",
    "  Based on the class Basket option\n",
    "  This class will simulate multiple baskets to train our model on\n",
    "  \"\"\"\n",
    "  def __init__(self, n_assets, n_samples):\n",
    "    \"\"\"\n",
    "    n_assets: number of assets contained in a portfolio ( basket )\n",
    "    n_samples : number of baskets we are simulating\n",
    "    \"\"\"\n",
    "    self.n_assets = n_assets\n",
    "    self.n_samples = n_samples\n",
    "\n",
    "    if (self.n_samples <= 0):\n",
    "      raise ValueError(\"n_samples needs to be positive\")\n",
    "\n",
    "    if (self.n_assets <= 0):\n",
    "      raise ValueError(\"n_assets needs to be positive\")  \n",
    "\n",
    "\n",
    "  def generate(self, corr=CORR, strike_price=BASE_STRIKE, base_price=BASE_PRICE, method='bs'):\n",
    "    \"\"\"\n",
    "    - method : refers to the solver that will compute the labels\n",
    "    it can be \"bs\" : for Black-Scholes or \"mc\" : Monte Carlo\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    mats = np.random.uniform(0.2, 1.1, size=self.n_samples)\n",
    "    vols = np.random.uniform(0.01, 1, size=self.n_samples)\n",
    "    rates = np.random.uniform(0.02, 0.1, size=self.n_samples)\n",
    "    \n",
    "    #add noise to strikes and prices\n",
    "    strikes = np.random.randn(self.n_samples) + strike_price\n",
    "    prices  = np.random.randn(self.n_samples) + base_price\n",
    "\n",
    "    if self.n_assets > 1:\n",
    "      weights = np.random.rand(self.n_samples * self.n_assets).reshape((self.n_samples, self.n_assets))\n",
    "      weights /= np.sum(weights, axis=1)[:, np.newaxis]\n",
    "    else:\n",
    "      weights = np.ones((self.n_samples, self.n_assets))\n",
    "\n",
    "    labels = []\n",
    "    for i in range(self.n_samples):\n",
    "      basket = BasketOption(weights[i], prices[i],\n",
    "                                  vols[i], corr, strikes[i], \n",
    "                                  mats[i], rates[i])\n",
    "      if method == \"bs\":\n",
    "        labels.append(basket.get_bs_price())\n",
    "      else: \n",
    "        labels.append(basket.get_mc())\n",
    "\n",
    "    print(len(labels))\n",
    "    self.data = pd.DataFrame({\n",
    "                         'S/K' : prices / strikes,\n",
    "                         'Maturity': mats,\n",
    "                         'Volatility': vols,\n",
    "                         'Rate': rates,\n",
    "                         'Labels': labels,\n",
    "                         'Prices': prices,\n",
    "                         'Strikes': strikes})\n",
    "    \n",
    "    for i in range(self.n_assets):\n",
    "      self.data['Weight_{}'.format(i)] = weights[:,i]\n",
    "\n",
    "    #save the dataframe to csv format\n",
    "    return self.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MWlUFyR73atR"
   },
   "source": [
    "Our Goal is to Build and train a neural network model for pricing European Basket options under Black-Scholes assumptions. So our ground truth will be generated using  Black-Scholes function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HVikyIUO0Dau"
   },
   "outputs": [],
   "source": [
    "def simulate(n_assets=3, n_samples=10000, method=\"bs\"):\n",
    "  \"\"\"\n",
    "  Generates data based on the Datagen class\n",
    "  args:\n",
    "  - n_assets : number of assets contained in a Basket\n",
    "  - n_samples : number of training examples\n",
    "  - method : method used to compute the price it can be \"mc\" or \"bs\"\n",
    "  \"\"\" \n",
    "  simulator = DataGen(3, n_samples=n_samples)\n",
    "  simulated_prices = simulator.generate(method=method)\n",
    "  return simulated_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 478
    },
    "id": "FnwmUvJM1Dk5",
    "outputId": "194d9d55-259d-4d94-e094-c2ed9881e088"
   },
   "outputs": [],
   "source": [
    "%time \n",
    "\n",
    "data = simulate()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xkHDZVz64rdb"
   },
   "source": [
    "# Choosing Model Features \n",
    "\n",
    "Based on this paper : https://canopee-group.com/wp-content/uploads/2020/12/Machine-Learning-methods-Coperneec.pdf\n",
    "\n",
    "The important features to consider for the model construction while dealing with European basket call (BS) \n",
    "are :\n",
    "\n",
    "- Maturity \n",
    "- Risk\n",
    "- the ratio S/k (Moneyness) \n",
    "- Volatility\n",
    "\n",
    "**Methodology**\n",
    "\n",
    "Before building the model we will be splitting our data then :          \n",
    "- Save train and test into csv formats\n",
    "- keep only the selected features\n",
    "\n",
    "**Model Description:**\n",
    "\n",
    "The model is build using the functional API of keras .\n",
    "It is composed of Dense layers, BatchNormalization layer and Dropout layer to prevent overfitting .\n",
    "The last layer is a Dense layer with 1 neuron as we are dealing with a regression problem and an activation function : relu because the Price option needs to be at least 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qAwmvLkU3Mie"
   },
   "outputs": [],
   "source": [
    "def split_data(data, split_ratio=0.7):\n",
    "  \"\"\"\n",
    "  splits the data into train and test\n",
    "  \n",
    "  args:\n",
    "  data : pd.Dataframe : represents simulated data\n",
    "  split_ratio: the factor to spli data into train and test\n",
    "\n",
    "  returns:\n",
    "  x_train, y_train, x_test, y_test\n",
    "  \"\"\"\n",
    "  train = data.iloc[:int(split_ratio * len(data)), :]\n",
    "  test  = data.iloc[int(split_ratio * len(data)):, :]\n",
    "  train.to_csv(\"train.csv\", index=False)\n",
    "  test.to_csv(\"test.csv\", index=False)\n",
    "  x_train, y_train = train.iloc[:, 0:4], train.iloc[:, 4]\n",
    "  x_test, y_test = test.iloc[:, 0:4], test.iloc[:, 4]\n",
    "  return x_train, y_train, x_test, y_test\n",
    "  \n",
    "x_train, y_train, x_test, y_test = split_data(data, split_ratio=0.7)\n",
    "\n",
    "def build_model(epochs=EPOCHS):\n",
    "  #build model using functional method\n",
    "  input = Input(shape=(x_train.shape[1],))\n",
    "  x = Dense(32, activation='relu')(input)\n",
    "  x = Dropout(0.2)(x)\n",
    "  x = Dense(64, activation='relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "  output = Dense(1, activation='relu')(x)\n",
    "\n",
    "  model = Model(inputs= input, outputs=output)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yY81058G5hgL",
    "outputId": "0e30d9cc-5980-4e61-9669-bfb846f0434c"
   },
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=\"adam\",\n",
    "              metrics=[\"mean_squared_error\"])\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=EPOCHS, validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M9rBfitSENFz"
   },
   "source": [
    "Compute Model Predictions on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w380qmcmEMVA",
    "outputId": "05f46785-d1b1-4950-aed8-120c4d58cb46"
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "predictions = model.predict(x_test)\n",
    "end = time.time()\n",
    "print(f\"Runtime of the model on test set is {end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def price_basket_nn(model, S=None, K=None, S_over_K=None, maturity=1.0, volatility=0.2, rate=0.01):\n",
    "    \"\"\"\n",
    "    Pricing helper basé sur le réseau de neurones entraîné.\n",
    "\n",
    "    On peut fournir directement S/K via `S_over_K`, ou bien S et K.\n",
    "    Les autres paramètres sont la maturité (en années), la volatilité et le taux sans risque.\n",
    "    \"\"\"\n",
    "    if S_over_K is None:\n",
    "        if S is None or K is None:\n",
    "            raise ValueError(\"Fournir soit S_over_K, soit (S et K).\")\n",
    "        S_over_K = S / K\n",
    "    x = np.array([[float(S_over_K), float(maturity), float(volatility), float(rate)]], dtype=float)\n",
    "    price = float(model.predict(x, verbose=0)[0, 0])\n",
    "    return price\n",
    "\n",
    "# Exemple d'appel :\n",
    "# price_basket_nn(model, S=100, K=200, maturity=0.5, volatility=0.3, rate=0.02)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qeRtGouM7cLo"
   },
   "source": [
    "# Optional : Model Performance plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h6ZDmF9S7QCI"
   },
   "outputs": [],
   "source": [
    "def plot_performance(history):\n",
    "  plt.plot(history.history['mean_squared_error'])\n",
    "  plt.plot(history.history['val_mean_squared_error'])\n",
    "  plt.ylabel('MAE')\n",
    "  plt.xlabel(\"epoch\")\n",
    "  plt.legend(['train', 'test'])\n",
    "  plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "id": "_4fuHycB7oN3",
    "outputId": "806e7fb7-e407-471a-b02a-785f6a6c0945"
   },
   "outputs": [],
   "source": [
    "plot_performance(history);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "raW-Lzt790ex",
    "outputId": "0b6ef63e-efef-46e1-8512-02ec317d4bc7"
   },
   "outputs": [],
   "source": [
    "print(\"maximum train option price :\" , y_train.max())\n",
    "print(\"mean train option price : \" , np.mean(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QwUCMp_t-R19"
   },
   "source": [
    "We notice that compared to the values of the dataset the MEA for the training data is pretty low for this simple regression model ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388
    },
    "id": "a3GnVnUu7tob",
    "outputId": "dc1b5d34-6017-47aa-cefe-2426e9080c9a"
   },
   "outputs": [],
   "source": [
    "#Plot test labels distribution\n",
    "sns.displot(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388
    },
    "id": "soKheaScEZj4",
    "outputId": "fde9a769-c779-42a0-810a-8a5b68f3cf1b"
   },
   "outputs": [],
   "source": [
    "#Plot prediction distribution\n",
    "sns.displot(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap du prix NN en fonction de S (spot) et K (strike) pour T = 1 an\n",
    "\n",
    "# Plage de S et K basée sur les quantiles des données\n",
    "S_min, S_max = data['Prices'].quantile([0.01, 0.99])\n",
    "K_min, K_max = data['Strikes'].quantile([0.01, 0.99])\n",
    "n_S = 50\n",
    "n_K = 50\n",
    "S_vals = np.linspace(S_min, S_max, n_S)\n",
    "K_vals = np.linspace(K_min, K_max, n_K)\n",
    "\n",
    "# Grille (S, K) : S en axe vertical, K en axe horizontal\n",
    "K_grid, S_grid = np.meshgrid(K_vals, S_vals)\n",
    "S_over_K_grid = S_grid / K_grid\n",
    "\n",
    "T_fixed = 1.0  # 1 an\n",
    "sigma_ref = float(data['Volatility'].median())\n",
    "rate_ref = float(data['Rate'].median())\n",
    "\n",
    "X_SK = np.stack([\n",
    "    S_over_K_grid.ravel(),\n",
    "    np.full(S_over_K_grid.size, T_fixed),\n",
    "    np.full(S_over_K_grid.size, sigma_ref),\n",
    "    np.full(S_over_K_grid.size, rate_ref),\n",
    "], axis=1)\n",
    "\n",
    "prices_SK = model.predict(X_SK, verbose=0).reshape(n_S, n_K)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "im2 = plt.imshow(\n",
    "    prices_SK,\n",
    "    origin='lower',\n",
    "    extent=[K_vals.min(), K_vals.max(), S_vals.min(), S_vals.max()],\n",
    "    aspect='auto',\n",
    "    cmap='viridis',\n",
    ")\n",
    "plt.xlabel('Strike K')\n",
    "plt.ylabel('Spot S')\n",
    "plt.title('Heatmap du prix NN en fonction de S et K (T=1 an)')\n",
    "plt.colorbar(im2, label='Prix NN')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rlkmCGfa-taK"
   },
   "source": [
    "# Compare prices to a traditional numerical solver such as Monte-Carlo, Finite Difference or any other methodology you may deem applicable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rCw9dFL4-z2P"
   },
   "source": [
    "In this part we will be using Monte Carlo for computing Basket option price.\n",
    "we will be working on testing set . So we will load the test set that we saved earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BVhRdpHHCUAw"
   },
   "source": [
    "**Methodology:**\n",
    "\n",
    "For making using of the MC simulations I used a function defined in this notebook  that uses MC for a call option : https://github.com/shrentseng/Numerical-methods-for-option-pricing/blob/main/Monte%20Carlo%20simulation%20option%20pricing.ipynb \n",
    "But as I am dealing with a Basket so when computing the payoff I need to pay attention to the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KhMlkUtl7o0J",
    "outputId": "84fc748b-b7f3-4dbc-d11a-badf0aa542da"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if os.path.exists(\"test.csv\"):\n",
    "  print(\"Downloading test csv file .......\") \n",
    "  test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "qaQ0Cp7KCAa7",
    "outputId": "5b31ff8e-e030-4841-bc1b-dde4043a1cfb"
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LMa3nF_TCJ25",
    "outputId": "24bb2fae-10c5-4141-eb7f-3be0f38f1a08"
   },
   "outputs": [],
   "source": [
    "#Define a Monte carlo MC price empty list \n",
    "%time \n",
    "start = time.time()\n",
    "mc_prices = []\n",
    "for i in range(test.shape[0]):\n",
    "    basket = BasketOption(\n",
    "        test.iloc[i,7:].to_numpy(),\n",
    "        test.iloc[i].Prices,\n",
    "        test.iloc[i].Volatility,\n",
    "        CORR,\n",
    "        test.iloc[i].Strikes,\n",
    "        test.iloc[i].Maturity,\n",
    "        test.iloc[i].Rate\n",
    "    )\n",
    "    mc_prices.append(basket.get_mc())\n",
    "end = time.time()\n",
    "print(f\"Runtime of MC is : .... {end - start}\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "emCHzNIxGe1U"
   },
   "source": [
    "# Compare to the case of 1 asset\n",
    "\n",
    "In the case of 1 asset the correlation matrix takes one value :\n",
    "\n",
    "So we will have same work as before with :\n",
    "\n",
    "- corr = np.array([[1,]]) \n",
    "- n_assets = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8A5zBHuLLgAo",
    "outputId": "24f26199-a7fe-4a7c-e2dd-745b68f881fe"
   },
   "outputs": [],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fck3OrmSGzch"
   },
   "source": [
    "Summary :\n",
    "\n",
    "The Main Goal of the client is explore novel methodologies for accelerating the pricing of exotic derivatives. The Client cares a lot about the time that an algorithm consumes to compute Option Price \n",
    "\n",
    "From  our experiment : with 10 000 data points and with 3000 data points on the test set the Neural network model needs  0.12 seconds to run and the MC algorithm needs 9.85 seconds to run.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ch8Up4LMEjdi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV Surface helpers (importés depuis iv_surface.ipynb)\n",
    "\n",
    "Ces fonctions permettent de charger un CSV Basket (colonnes `Strikes`, `Maturity`, `Volatility`)\n",
    "et d'afficher une surface de volatilité implicite (3D + heatmap).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def build_grid(\n",
    "    df: pd.DataFrame,\n",
    "    S0: float,\n",
    "    n_K: int = 200,\n",
    "    n_T: int = 200,\n",
    "    K_min: float | None = None,\n",
    "    K_max: float | None = None,\n",
    "    T_min: float | None = None,\n",
    "    T_max: float | None = None,\n",
    "    K_span: float | None = None,\n",
    "    margin_frac: float = 0.02,\n",
    "):\n",
    "    \"\"\"Construit une grille régulière (K, T) et moyenne les IV dans chaque cellule.\n",
    "\n",
    "    - Si `K_min/K_max` ne sont pas fournis, on les déduit des données avec une marge.\n",
    "    - Sinon, on peut forcer une fenêtre via `K_span` autour de `S0`.\n",
    "    - Les bornes en maturité sont par défaut celles du dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    if K_min is None or K_max is None:\n",
    "        if K_span is not None:\n",
    "            K_min = S0 - K_span\n",
    "            K_max = S0 + K_span\n",
    "        else:\n",
    "            data_K_min = float(df[\"K\"].min())\n",
    "            data_K_max = float(df[\"K\"].max())\n",
    "            delta_K = data_K_max - data_K_min\n",
    "            pad = delta_K * margin_frac\n",
    "            K_min = data_K_min - pad\n",
    "            K_max = data_K_max + pad\n",
    "\n",
    "    if T_min is None:\n",
    "        T_min = float(df[\"T\"].min())\n",
    "    if T_max is None:\n",
    "        T_max = float(df[\"T\"].max())\n",
    "\n",
    "    if K_min >= K_max:\n",
    "        raise ValueError(\"K_min doit être inférieur à K_max.\")\n",
    "    if T_min >= T_max:\n",
    "        raise ValueError(\"T_min doit être inférieur à T_max.\")\n",
    "\n",
    "    K_vals = np.linspace(K_min, K_max, n_K)\n",
    "    T_vals = np.linspace(T_min, T_max, n_T)\n",
    "\n",
    "    df = df[(df[\"K\"] >= K_min) & (df[\"K\"] <= K_max)].copy()\n",
    "    df = df[(df[\"T\"] >= T_min) & (df[\"T\"] <= T_max)]\n",
    "\n",
    "    if df.empty:\n",
    "        raise ValueError(\"Aucun point n'appartient au domaine défini par la grille.\")\n",
    "\n",
    "    df[\"K_idx\"] = np.searchsorted(K_vals, df[\"K\"], side=\"left\").clip(0, n_K - 1)\n",
    "    df[\"T_idx\"] = np.searchsorted(T_vals, df[\"T\"], side=\"left\").clip(0, n_T - 1)\n",
    "\n",
    "    grouped = df.groupby([\"T_idx\", \"K_idx\"])[\"iv\"].mean().reset_index()\n",
    "\n",
    "    iv_grid = np.full((n_T, n_K), np.nan, dtype=float)\n",
    "    for _, row in grouped.iterrows():\n",
    "        iv_grid[int(row[\"T_idx\"]), int(row[\"K_idx\"])] = row[\"iv\"]\n",
    "\n",
    "    K_grid, T_grid = np.meshgrid(K_vals, T_vals)\n",
    "    return K_grid, T_grid, iv_grid\n",
    "\n",
    "def plot_surface(K_grid, T_grid, iv_grid, title_suffix=\"\"):\n",
    "    \"\"\"Affiche surface 3D + heatmap 2D de la volatilité implicite.\"\"\"\n",
    "    fig = plt.figure(figsize=(12, 5))\n",
    "\n",
    "    ax3d = fig.add_subplot(1, 2, 1, projection=\"3d\")\n",
    "    iv_flat = iv_grid[~np.isnan(iv_grid)]\n",
    "    if iv_flat.size == 0:\n",
    "        raise ValueError(\"La grille IV est entièrement vide.\")\n",
    "    iv_mean = iv_flat.mean()\n",
    "    iv_fill = np.where(np.isnan(iv_grid), iv_mean, iv_grid)\n",
    "\n",
    "    surf = ax3d.plot_surface(\n",
    "        K_grid,\n",
    "        T_grid,\n",
    "        iv_fill,\n",
    "        rstride=1,\n",
    "        cstride=1,\n",
    "        linewidth=0.2,\n",
    "        antialiased=True,\n",
    "        cmap=\"viridis\",\n",
    "    )\n",
    "    ax3d.set_xlabel(\"Strike K\")\n",
    "    ax3d.set_ylabel(\"Maturité T (années)\")\n",
    "    ax3d.set_zlabel(\"Implied vol\")\n",
    "    ax3d.set_title(f\"Surface IV 3D{title_suffix}\")\n",
    "    fig.colorbar(surf, ax=ax3d, shrink=0.6, aspect=10, label=\"iv\")\n",
    "\n",
    "    ax2d = fig.add_subplot(1, 2, 2)\n",
    "    im = ax2d.imshow(\n",
    "        iv_fill,\n",
    "        extent=[K_grid.min(), K_grid.max(), T_grid.min(), T_grid.max()],\n",
    "        origin=\"lower\",\n",
    "        aspect=\"auto\",\n",
    "        cmap=\"viridis\",\n",
    "    )\n",
    "    ax2d.set_xlabel(\"Strike K\")\n",
    "    ax2d.set_ylabel(\"Maturité T (années)\")\n",
    "    ax2d.set_title(f\"Heatmap IV{title_suffix}\")\n",
    "    fig.colorbar(im, ax=ax2d, label=\"iv\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def load_iv_dataframe(csv_path: Path):\n",
    "    \"\"\"Charge un CSV Basket/data et renvoie (df_iv, S0_estime).\n",
    "    Attend les colonnes 'Strikes', 'Maturity', 'Volatility'.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    required_cols = {\"Strikes\", \"Maturity\", \"Volatility\"}\n",
    "    if not required_cols.issubset(df.columns):\n",
    "        raise ValueError(f\"Colonnes manquantes: {required_cols - set(df.columns)}\")\n",
    "\n",
    "    df_iv = pd.DataFrame({\n",
    "        \"K\": df[\"Strikes\"],\n",
    "        \"T\": df[\"Maturity\"],\n",
    "        \"iv\": df[\"Volatility\"],\n",
    "    })\n",
    "\n",
    "    if \"Prices\" in df.columns:\n",
    "        S0 = float(df[\"Prices\"].mean())\n",
    "    elif \"S/K\" in df.columns and \"Strikes\" in df.columns:\n",
    "        S0 = float((df[\"S/K\"] * df[\"Strikes\"]).mean())\n",
    "    else:\n",
    "        S0 = float(df[\"Strikes\"].mean())\n",
    "\n",
    "    return df_iv, S0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple d'utilisation avec un CSV (train.csv de simulation)\n",
    "csv_iv = Path('train.csv')\n",
    "if csv_iv.exists():\n",
    "    iv_df, S0_est = load_iv_dataframe(csv_iv)\n",
    "    K_grid, T_grid, iv_grid = build_grid(iv_df, S0=S0_est, n_K=150, n_T=150)\n",
    "    plot_surface(K_grid, T_grid, iv_grid, title_suffix=' - train.csv')\n",
    "else:\n",
    "    print(f'Fichier introuvable: {csv_iv}')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Basket_Pricing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "americanOption",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
