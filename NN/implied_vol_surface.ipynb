{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Black\u2013Scholes Implied Volatility Surface\n",
        "This notebook walks through the complete workflow of loading option quotes, computing Black\u2013Scholes implied volatilities, reshaping them into a surface, and visualizing the results. Each step is self-contained and heavily commented so it can serve as both documentation and a reusable analysis template."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Imports and global configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "# Core scientific stack\n",
        "import math\n",
        "from math import exp, log, sqrt\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401 (needed for 3D projection side effects)\n",
        "from scipy.optimize import brentq\n",
        "\n",
        "# Global plotting and display parameters\n",
        "plt.style.use(\"seaborn-v0_8\")\n",
        "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
        "np.set_printoptions(precision=6, suppress=True)\n",
        "pd.options.display.float_format = lambda x: f\"{x:,.6f}\"\n",
        "\n",
        "print(\"Libraries imported successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load option CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Path to the CSV sitting next to this notebook. Adjust if your data lives elsewhere.\n",
        "CSV_PATH = \"options_sample_200.csv\"\n",
        "\n",
        "# Read the dataset and perform quick sanity checks.\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "expected_cols = {\"S0\", \"K\", \"C_mkt\", \"T\"}\n",
        "missing = expected_cols - set(df.columns)\n",
        "if missing:\n",
        "    raise ValueError(f\"CSV is missing required columns: {missing}\")\n",
        "\n",
        "print(f\"Loaded {CSV_PATH} with shape {df.shape}.\")\n",
        "display(df.head())\n",
        "print(\"\nDescriptive statistics:\")\n",
        "display(df.describe(include='all'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Black\u2013Scholes helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Normal CDF -------------------------------------------------------\n",
        "def normal_cdf(x: float) -> float:\n",
        "    \"\"\"Return Phi(x), the standard normal cumulative distribution function.\"\"\"\n",
        "    return 0.5 * (1.0 + math.erf(x / math.sqrt(2.0)))\n",
        "\n",
        "\n",
        "# --- Black-Scholes call price ----------------------------------------\n",
        "def bs_call(S0: float, K: float, T: float, r: float, q: float, vol: float) -> float:\n",
        "    \"\"\"Price a European call with the classic Black-Scholes closed form.\"\"\"\n",
        "    if T <= 0:\n",
        "        # At expiry we fall back to intrinsic value discounted appropriately.\n",
        "        return max(S0 * math.exp(-q * T) - K * math.exp(-r * T), 0.0)\n",
        "    vol = max(vol, 1e-10)  # Numerical guard to avoid division by zero.\n",
        "    sqrt_T = math.sqrt(T)\n",
        "    d1 = (math.log(S0 / K) + (r - q + 0.5 * vol * vol) * T) / (vol * sqrt_T)\n",
        "    d2 = d1 - vol * sqrt_T\n",
        "    discount_domestic = math.exp(-r * T)\n",
        "    discount_foreign = math.exp(-q * T)\n",
        "    price = S0 * discount_foreign * normal_cdf(d1) - K * discount_domestic * normal_cdf(d2)\n",
        "    return price\n",
        "\n",
        "\n",
        "# --- Implied volatility solver ---------------------------------------\n",
        "def implied_vol_bs(C_mkt: float, S0: float, K: float, T: float, r: float, q: float = 0.0) -> float:\n",
        "    \"\"\"Invert the Black-Scholes formula via a safeguarded Brent search.\"\"\"\n",
        "    # Guardrails: handle degenerate maturities or absurd prices early.\n",
        "    if T <= 0 or C_mkt <= 0:\n",
        "        return float(\"nan\")\n",
        "\n",
        "    # Intrinsic value bound: if the market price violates it, exit gracefully.\n",
        "    intrinsic = max(S0 * math.exp(-q * T) - K * math.exp(-r * T), 0.0)\n",
        "    if C_mkt < intrinsic - 1e-8:\n",
        "        return float(\"nan\")\n",
        "\n",
        "    # Objective for root finding: price(vol) - market price.\n",
        "    def objective(vol: float) -> float:\n",
        "        return bs_call(S0, K, T, r, q, vol) - C_mkt\n",
        "\n",
        "    vol_low, vol_high = 1e-4, 0.5  # Sensible starting bracket.\n",
        "    price_high = bs_call(S0, K, T, r, q, vol_high)\n",
        "    # Expand the upper bracket until we dominate the market price or hit a cap.\n",
        "    while price_high < C_mkt and vol_high < 10.0:\n",
        "        vol_high *= 2.0\n",
        "        price_high = bs_call(S0, K, T, r, q, vol_high)\n",
        "\n",
        "    if price_high < C_mkt:\n",
        "        return float(\"nan\")\n",
        "\n",
        "    try:\n",
        "        return brentq(objective, vol_low, vol_high, xtol=1e-8, rtol=1e-8, maxiter=200)\n",
        "    except ValueError:\n",
        "        return float(\"nan\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Compute implied volatility column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Constant short rate used throughout the analysis. Adjust here if needed.\n",
        "risk_free_rate = 0.02\n",
        "dividend_yield = 0.0\n",
        "\n",
        "sigmas = []\n",
        "for idx, row in df.iterrows():\n",
        "    sigma = implied_vol_bs(row[\"C_mkt\"], row[\"S0\"], row[\"K\"], row[\"T\"], risk_free_rate, dividend_yield)\n",
        "    sigmas.append(sigma)\n",
        "\n",
        "df[\"sigma_BS\"] = sigmas\n",
        "print(\"Implied volatilities computed.\")\n",
        "display(df.head())\n",
        "\n",
        "print(\"\nSigma summary statistics:\")\n",
        "display(df[\"sigma_BS\"].describe())\n",
        "\n",
        "print(\"\nMissing values per column (post-sigma computation):\")\n",
        "display(df.isna().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Reshape into surface grids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute moneyness S0/K for each quote.\n",
        "df[\"moneyness\"] = df[\"S0\"] / df[\"K\"]\n",
        "\n",
        "# Sorted grids for strikes, maturities, and moneyness.\n",
        "K_grid = np.sort(df[\"K\"].unique())\n",
        "T_grid = np.sort(df[\"T\"].unique())\n",
        "m_grid = np.sort(df[\"moneyness\"].unique())\n",
        "\n",
        "# Pivot tables for different visualizations.\n",
        "sigma_surface_m = df.pivot_table(index=\"T\", columns=\"moneyness\", values=\"sigma_BS\")\n",
        "sigma_surface_k = df.pivot_table(index=\"T\", columns=\"K\", values=\"sigma_BS\")\n",
        "\n",
        "print(\"Surface matrix (rows = T, columns = moneyness):\")\n",
        "display(sigma_surface_m.head())\n",
        "\n",
        "print(\"\nSurface matrix (rows = T, columns = strikes K):\")\n",
        "display(sigma_surface_k.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Plot implied volatility surfaces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- 3D surface: moneyness vs maturity vs implied vol ----------------\n",
        "T_vals = sigma_surface_m.index.values\n",
        "M_vals = sigma_surface_m.columns.values\n",
        "TT, MM = np.meshgrid(T_vals, M_vals, indexing=\"ij\")\n",
        "ZZ = sigma_surface_m.values\n",
        "\n",
        "# Replace NaNs with the column mean to keep the surface continuous.\n",
        "Z_filled = np.array(ZZ, copy=True)\n",
        "col_means = np.nanmean(Z_filled, axis=0)\n",
        "inds = np.where(np.isnan(Z_filled))\n",
        "if inds[0].size > 0:\n",
        "    Z_filled[inds] = np.take(col_means, inds[1])\n",
        "\n",
        "fig = plt.figure(figsize=(12, 7))\n",
        "ax = fig.add_subplot(111, projection=\"3d\")\n",
        "surf = ax.plot_surface(MM, TT, Z_filled, cmap=cm.viridis, edgecolor=\"none\")\n",
        "ax.set_title(\"Black\u2013Scholes Implied Vol Surface\")\n",
        "ax.set_xlabel(\"Moneyness S0/K\")\n",
        "ax.set_ylabel(\"Maturity T (years)\")\n",
        "ax.set_zlabel(\"Implied vol \u03c3_BS\")\n",
        "fig.colorbar(surf, shrink=0.6, aspect=15, label=\"\u03c3_BS\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- 2D heatmap: strikes vs maturity ---------------------------------\n",
        "T_vals_k = sigma_surface_k.index.values\n",
        "K_vals = sigma_surface_k.columns.values\n",
        "K_mesh, T_mesh = np.meshgrid(K_vals, T_vals_k)\n",
        "ZK = sigma_surface_k.values\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 5))\n",
        "cmap_plot = ax.pcolormesh(K_mesh, T_mesh, ZK, shading=\"auto\", cmap=cm.magma)\n",
        "ax.set_title(\"Black\u2013Scholes Implied Volatility Heatmap\")\n",
        "ax.set_xlabel(\"Strike K\")\n",
        "ax.set_ylabel(\"Maturity T (years)\")\n",
        "fig.colorbar(cmap_plot, ax=ax, label=\"\u03c3_BS\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Optional diagnostics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Scatter plot of (moneyness, maturity) colored by implied vol.\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "scatter = ax.scatter(df[\"moneyness\"], df[\"T\"], c=df[\"sigma_BS\"], cmap=cm.viridis, s=50, edgecolor=\"k\")\n",
        "ax.set_title(\"Implied Volatility Scatter\")\n",
        "ax.set_xlabel(\"Moneyness S0/K\")\n",
        "ax.set_ylabel(\"Maturity T (years)\")\n",
        "fig.colorbar(scatter, ax=ax, label=\"\u03c3_BS\")\n",
        "plt.show()\n",
        "\n",
        "# Simple outlier detection based on a symmetric 3-sigma rule.\n",
        "sigma_mean = df[\"sigma_BS\"].mean()\n",
        "sigma_std = df[\"sigma_BS\"].std()\n",
        "upper_cut = sigma_mean + 3 * sigma_std\n",
        "lower_cut = max(sigma_mean - 3 * sigma_std, 0.0)\n",
        "outliers = df[(df[\"sigma_BS\"] > upper_cut) | (df[\"sigma_BS\"] < lower_cut)]\n",
        "\n",
        "print(f\"Detected {len(outliers)} potential \u03c3 outliers (3-sigma rule).\")\n",
        "if not outliers.empty:\n",
        "    print(outliers[[\"S0\", \"K\", \"T\", \"sigma_BS\"]].to_string(index=False))\n",
        "else:\n",
        "    print(\"No extreme implied vols found.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Takeaways\n",
        "The implied volatility surface above summarises how option prices embed expectations about future variance. Higher moneyness (deep ITM calls) usually compresses \u03c3, while deep OTM regions inflate it; maturity adds term-structure effects where long expiries smooth short-term spikes. Always keep in mind that market noise, sparse strike/maturity grids, and the Black\u2013Scholes framework itself (constant volatility, no jumps) limit the precision of this reconstruction, so further modelling such as local or stochastic volatility is often warranted."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}